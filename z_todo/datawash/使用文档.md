# 使用文档

# wash.py

## 1) 核心功能

- **输入**：`.txt`或`.pdf` 文件及文件夹。
- **处理**：文本提取 → 繁简转换 → 深度清洗 → 隐私脱敏 → 质量过滤。
- **输出**：流式返回清洗后的`.txt`文件（自动触发下载），文件名为`cleaned_原始文件名.txt`。
- **主要特性**：
  - **PDF 智能处理**：自动去除页眉（顶部 60pt）和页脚（底部 50pt），仅保留正文文本块。
  - **隐私安全**：自动检测并替换邮箱为`[EMAIL]`，手机号为`[MOBILEPHONE]`。
  - **文本规范**：强制进行 Unicode (NFKC) 标准化及繁体转简体（OpenCC）。
  - **质量控制**：自动丢弃有效字符密度低于 30% 的乱码行或噪声行。

***

## 2) 安装与启动

### 安装依赖

```python 
pip install pymupdf opencc tqdm
```


### 启动参数

| **参数**​      | **必填**​ | **说明**​       | **示例**​                         |
| ------------ | ------- | ------------- | ------------------------------- |
| \`--input\`  | 是       | 输入的文件路径或文件夹路径 | \`--input ./raw\_data\`         |
| \`--output\` | 是       | 清洗结果存放的文件夹路径  | \`--output ./cleaned\_storage\` |

## 3) 使用说明

### 1. 核心大脑：`DataCleaner` 类

这是所有文本必须要经过的“净化车间”，包含 4 个步骤的流水线：

- **Step 1: 标准化 (Normalization)**
  - 使用`unicodedata.normalize('NFKC', line)`：把全角字符转半角（如`Ａ`->`A`，`１`->`1`），统一各种怪异的 Unicode 编码。
  - 使用`OpenCC('t2s')`：将繁体中文强制转换为简体中文。
- **Step 2: 去噪 (Denoising)**
  - **正则替换**：移除 URL 链接（http/https...）和 HTML 标签（`<div...>`）。
  - **字符过滤**：移除不可见控制字符（Unicode Category "C"），但特意保留了换行符`\n`、制表符`\t`。
- **Step 3: 脱敏 (Desensitization)**
  - 使用正则表达式匹配邮箱和手机号，分别替换为占位符`[EMAIL]`和`[MOBILEPHONE]`，保护隐私。
- **Step 4: 质量过滤 (Quality Check)**
  - 算法：计算一行文本中“有效字符”（中文+英文+数字+标点）的占比。
  - 阈值：如果无效字符（如乱码、特殊符号）占比超过 70%（即有效率 < 0.3），该行会被直接丢弃，防止脏数据污染模型。

### 2. 提取器：`PDFProcessor` 类

专门处理 PDF 格式的复杂性：

- **布局分析**：使用`fitz`(PyMuPDF) 的`get_text("blocks")` 方法获取文本块。
- **物理裁剪**：
  - 定义了`header_height = 60`和`footer_height = 50`。
  - 凡是坐标位于页面顶部 60pt 或底部 50pt 区域内的文本，一律视为页眉页脚，直接丢弃。
- **过滤图片**：忽略`block_type == 1` 的图片块，只提取文本。
- **行级清洗**：提取出的文本块会再次被拆分成行，送入`DataCleaner` 进行上述的 4 步清洗。

### 3. 读取器：`TXTProcessor` 类

处理纯文本文件的编码问题：

- **智能解码**：优先尝试`utf-8`解码；如果失败（报错 UnicodeDecodeError），自动回退尝试`gbk` 解码。这解决了 Windows 记事本保存的文件在 Linux/Mac 上可能乱码的问题。

### 4. 主流程 (`main` 函数)

1. **参数解析**：使用`argparse` 处理命令行输入。
2. **文件扫描**：使用`pathlib`递归扫描输入目录下的所有`.pdf`和`.txt`。
3. **进度显示**：使用`tqdm` 展示处理进度条。
4. **结果保存**：将清洗后的内容写入输出目录，文件名统一加前缀`cleaned_`。

## auto\_run.py

这是一个“一键式”流水线脚本，它将`wash.py`（清洗）和`generate_alpaca_jsonl.py`（生成）串联起来，实现从原始文件到最终数据集的全自动处理。

### 1) 核心功能

- **自动化流程**：
  1. 调用`wash.py` 将原始数据清洗并存入临时目录。
  2. 自动获取清洗后的文件路径。
  3. 调用`generate_alpaca_jsonl.py` 读取清洗后的数据，生成 Alpaca 格式数据集。
- **无缝衔接**：无需人工干预文件的传递过程。

### 2) 配置说明 (在代码内修改)

打开`auto_run.py`文件，修改顶部的**配置区**：

```python 
# ================= 配置区 =================
# 1. 输入文件：修改为你实际的文件名或者文件夹
RAW_INPUT = os.path.join(BASE_DIR, "test_data.txt") 

# 2. 中转目录：清洗后的文件存放位置（脚本会自动创建）
CLEANED_DIR = os.path.join(BASE_DIR, "cleaned_storage")

# 3. 最终输出：生成的 jsonl 文件名
FINAL_OUTPUT = os.path.join(BASE_DIR, "final_dataset.jsonl")
# ==========================================
```


- 确保`wash.py`和`generate_alpaca_jsonl.py` 与本脚本在同一目录下（或路径配置正确）。
- 确保原始文件（如`test_data.txt`）真实存在于脚本指定的位置。
