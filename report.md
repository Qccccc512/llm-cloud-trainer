# 云计算大作业项目报告：大模型训练云服务化（LLM-Cloud-Trainer）

> 项目定位：基于 LLaMA-Factory 二次开发的“训练-评测-导出-部署-对话”全链路云服务化平台。
>
> 特点：零代码体验大模型训练、评估、在线推理对话全流程。一主多辅架构，Worker 数量可便捷扩展。

## 0. 我们相对“单机跑一个 LLaMA-Factory”做了什么？达到了什么效果？

LLaMA-Factory 本身已经提供 WebUI，并不一定要求用户“手敲命令”。但在真实训练使用中，单机形态仍存在两个明显门槛：

1) **易用性门槛**：原生的 WebUI 参数项非常多、表单密度高，功能分区做得并不好，新手需要理解大量训练细节才能正确、高效地填写；
2) **可用性门槛**：单机部署受限于本机算力与运行环境，用户必须在符合算力需求与运行环境要求的机器上操作；想要“随时随地按需使用/多人共享/远程调度”，往往需要额外工程化。

而本项目在保留 LLaMA-Factory 作为底层训练/评测/导出/推理引擎的同时，重点补齐了“云服务化”必须的控制面与接入面能力，并对交互体验做了产品化改造：

### 0.1 我们开发了什么内容（核心增量）

- **Master 控制面（Control Plane）**：提供统一 API 与权限控制，维护任务/评测/导出/部署会话的状态机，选择 Worker 分发任务，并聚合日志。
- **Worker 执行面（Data Plane）**：将“手工命令行运行 LLaMA-Factory”封装为 HTTP 服务；通过 Docker SDK 拉起容器，挂载共享目录，持续落盘日志并上报心跳与资源。
- **前端 UI（单页应用）**：重做更直观的训练表单与流程编排，仅暴露关键参数、引导新手关注核心问题，同时保留 `config_overrides`（额外参数）入口，以供进阶用户自由配置使用；并提供任务列表、实时日志、在线评测/导出/部署/对话、数据集管理、数据清洗/生成/增强等功能，优化服务体验。
- **数据集与数据工程能力**：以数据库管理 Dataset 元数据，并同步 dataset_info.json；在平台内完成数据集预览/下载/清洗/生成/增强，形成“数据→训练”的闭环。
- **模型资产管理**：以数据库管理 ModelRegistry 元数据，约束模型来源并支撑训练/评测/导出/部署选择。
- **一键运维脚本**：提供 master/worker 的启动/停止/重启脚本，便于演示与部署。

### 0.2 实现了什么效果（可观察结果）

- **训练云服务化**：用户通过网页注册、登录并提交训练参数，系统自动生成 YAML 配置文件、调度 Worker、运行容器，实时查看日志，训练完成后可一键下载产物 zip。
- **随时随地按需使用**：服务化后用户只需网络与账号即可提交任务与查看日志，不再绑定某一台训练机器的本地环境；资源可由后端 Worker 统一承载与扩展。
- **数据到训练闭环**：用户可在平台内对数据集进行预览/下载，并对私有数据（如txt、pdf文档）执行清洗、从txt文本生成 Alpaca JSONL、对 Alpaca 数据做增强，直接产出新数据集条目用于训练/评测。
- **全链路能力可用**：训练 / 评测 / 导出 / 在线部署 / 对话测试形成闭环，减少“训练完不知道能不能用”的断点。
- **多用户隔离**：登录后按 token 限制访问自己的任务、日志、下载与导出/评测记录，避免不同用户互相干扰。
- **可扩展到多机**：逻辑结构已拆为 Master/Worker，并支持通过配置指定 URL；一键配置环境依赖后，只需设置共享存储、拉取 worker 脚本和容器镜像、启动 worker 连通 master，即可完成 worker 数目扩展。

### 0.3 云服务化完成度

- 已完成：服务化接入（Web/API）、任务状态管理、远程执行、日志聚合、基础资源监控、数据集管理与数据处理闭环、推理会话管理。
- 待后续迭代：更强的调度公平性、更细粒度的调度以支持更多并发、容错重试、HA、审计与更细粒度安全、可观测性曲线与保留策略。

### 0.4 “手搓版” vs “k8s + 消息队列”等高级技术的优缺点

**我们的手搓版优点：适合课程作业与单机/小集群的测试环境**

- **依赖少、部署轻**：FastAPI + SQLite + Docker 即可跑通，不需要搭 K8s、MQ、服务发现、Ingress 等复杂组件。
- **端到端可控**：链路短、调试成本低，适合在
服务器上快速迭代与演示。
- **贴近实际业务**：覆盖鉴权、调度、日志、资产管理、下载等“平台化必需品”，接近云服务产品形态。

**缺点：与 k8s+MQ 的差距**

- **扩展性与吞吐有限**：缺少队列与工作池模型，任务并发/公平调度/抢占难做；多机扩展依赖额外工程。
- **高可用不足**：Master/DB 单点，故障恢复能力弱；缺少标准化的副本/健康检查/自动重启体系。
- **隔离与安全弱于云原生**：容器权限、网络策略、Secret 管理、审计等能力不如 K8s 的成熟生态。
- **可观测性不足**：缺少 Prometheus/Grafana、集中日志、Tracing 等体系化能力。

总结：本项目选择“轻量但完整”的平台化路径，优先交付可用且功能丰富的云服务闭环。

---

## 1. 项目背景与目标

### 1.1 背景

大模型微调通常需要复杂的参数配置、数据集注册、长时间训练与日志追踪；训练后还需要评测、导出与部署验证。单机脚本化方式难以支持多用户与远程协作。

### 1.2 目标

- 将 LLaMA-Factory 的能力服务化，形成“训练-评测-导出-部署-对话”闭环。
- 提供大模型从构建数据集、训练、评估到部署使用全流程的统一入口（Web/API）、多租户隔离、鉴权、任务状态管理、日志查看。
- 先在单机上模拟分布式架构，迭代实现真正的分布式多 Worker 扩展能力。

---

## 2. 总体架构与关键设计

### 2.1 三层逻辑架构

- **Frontend**：用户交互与可视化。
- **Master**：鉴权、任务状态机、调度、日志代理、资产管理。
- **Worker**：容器运行时执行器，负责拉起训练/评测/导出/推理容器并向 master 回报状态和任务结果。

### 2.2 通信与数据流

- Frontend → Master：REST + WebSocket（任务提交、列表、日志、下载）。
- Master → Worker：REST（下发执行 YAML、查询状态、推理转发）。
- Worker → Master：心跳与状态上报（含 CPU/内存/GPU 指标）。
- 存储：共享目录 `cloud-llm/{data,output,logs,checkpoints,hf-cache,temp}`；容器内映射 `/app/{data,output,logs,checkpoints,temp}`，`hf-cache` 挂载到容器内 `/root/.cache/huggingface`（复用 HuggingFace 权重/数据缓存）。
- 多机共享：将共享目录部署在 NFS 挂载点上，从而实现数据、模型、产物的跨 Worker 复用。

---

## 3. 核心功能实现

### 3.1 任务全生命周期管理（训练）

- 前端表单收集关键参数；Master 生成训练 YAML；写入任务记录并调度 Worker。
- Worker 使用 Docker SDK 启动训练容器，挂载共享目录与 HF cache。
- Master/Worker 通过“回调上报 + 兜底轮询”收敛任务状态（pending/running/success/failed）。
- 训练输出落盘后，Master 提供 zip 下载接口。

### 3.2 实时日志：WebSocket 代理

- Worker 将容器日志持续落盘为 `logs/<task_id>.log`。
- Worker 提供 `/task/{task_id}/log` WebSocket，支持 tail + follow。
- Master 提供 `/ws/task/{task_id}/log` 代理，让前端无需知道 Worker 地址。

### 3.3 在线推理部署与对话（Playground）

- Master 创建推理部署会话（同一用户单实例），生成推理 YAML 并下发到 Worker。
- Worker 拉起推理容器并做就绪探测（TCP + `/v1/chat/completions`），成功后返回端口。
- Master 作为统一入口转发 `/inference/chat`，前端提供对话 UI 与会话持久化。
- Worker 支持推理容器的空闲自动卸载（默认 5 分钟）。

### 3.4 评测与导出

- 评测：Master 创建 EvalJob，下发 YAML 到 Worker，输出可下载。
- 导出：Master 创建 ExportJob，下发 YAML 到 Worker，支持 bitsandbytes 量化路径并提供下载；导出成功后可在前端“我的模型/可选模型来源”中直接使用（无需额外手工登记）。

### 3.5 数据集管理与数据处理闭环（清洗/生成/增强）

- 数据集注册/上传由 Master 统一管理（public/private + owner_id），并提供预览与下载接口。
- 数据集变更同步写回 `cloud-llm/data/dataset_info.json`，供训练/评测容器直接识别。
- 对私有数据集提供三类“派生数据集”能力（平台内一键执行，产物自动注册为新的 Dataset）：
	- **清洗**：调用本地脚本对输入文本做清洗，输出 `cleaned_*.txt`，用于后续生成/训练。
	- **生成**：从文本调用外部 LLM API 生成 Alpaca 格式 `.jsonl` 数据集。
	- **增强**：对 Alpaca/指令数据做扩增与相似度过滤，输入`.json`/`.jsonl`，输出增强后的 `.jsonl` 数据集。
- 安全与可运维性：API key 仅由前端提交给 Master 并传给子进程，服务端不回显、不打印到日志（避免泄露）。

### 3.6 资源监控（基础版）

- Worker 心跳上报 GPU 利用率/显存/温度，以及 CPU/内存。
- Master 记录 Worker 当前资源与 ResourceMetric。
- 前端展示平台当前的 Worker 列表、状态与关键指标。

---

## 4. 关键技术点与工程化细节

### 4.1 YAML 模板 + 深度合并

平台不暴露 LLaMA-Factory 全量参数，而是：

- 提供基础模板 `master/templates/*.yaml` 作为默认配置。
- 表单映射到少量关键字段。
- 允许用户通过 `config_overrides` 进行深度覆写，兼顾易用性与可扩展性。

### 4.2 权限模型与安全收敛

- 登录/注册：邀请码校验 + token（Bearer）鉴权。
- 任务/日志/下载：按 user_id 隔离。
- 模型来源约束：训练/评测/导出/部署限定为预置模型或本人产物，降低任意路径执行的风险。
- ModelScope 扩展：支持通过前端“自定义参数/覆写配置”透传 ModelScope 相关字段（例如将 `model_name_or_path` 指向 ms 标识或配置下载参数），以适配不同模型源。

### 4.3 运维与部署

- `scripts/manage_services.sh` 提供一键启停 master/worker。
- 路径通过环境变量覆写，已支持将共享目录放在 NFS 挂载点上以实现多机共享。
- 基于 llama-factory 的官方镜像，对其内部环境重新配置后制作为新镜像，worker 可从 master 端拉取镜像到本地使用。
- 

---

## 5. 运行与演示

1) 启动服务：使用脚本启动 master 与 worker。
2) 打开 Web 首页：注册/登录。
3) 数据集：浏览公共数据集，上传私有数据集，使用“预览/下载”确认内容。
4) 数据处理：对私有数据集执行清洗/生成/增强，得到派生数据集条目。
5) 训练：选择模型与（原始或派生）数据集，提交任务，观察日志与状态，下载产物。
6) 评测：选择模型（预置/训练产物/导出产物），提交评测并下载输出。
7) 导出：对训练产物做合并/量化导出，下载导出包。
8) 部署与对话：部署模型并在 Playground 中对话验证。

---

## 6. 局限性与后续迭代方向

- 调度公平性
- 并发性能优化
- Worker 离线重试与更强容错。
- 模型库管理增强：前端可编辑/双向校验、按用户/可见性分组等（避免全局模型表带来的权限复杂度）。
- ModelScope 的“一等公民化”：虽然已可通过自定义参数透传使用，但仍可进一步做成可视化选择、可校验、可一键下载/缓存的流程。
- 指标规范化与可视化（曲线、告警、保留策略）。
- 更完善的安全收敛（脱敏 Worker 内网地址、审计与权限细化）。

---

## 7. 总结

本项目以 LLaMA-Factory 为底座，补齐了训练云服务化最关键的“控制面 + 执行面 + 前端接入面”，实现了从训练到部署对话的全链路闭环。相比云原生全家桶方案，本项目用更轻量的工程代价，换取了更快的迭代速度、可用且丰富的服务化体验与可演示性。